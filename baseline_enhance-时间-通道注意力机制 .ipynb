{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 上分思路\n",
    "- 数据\n",
    "- 模型\n",
    "- 损失函数\n",
    "- 训练方式\n",
    "- 超参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **第一步**\n",
    "在运行环境中安装对应的库 执行该命令即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T15:47:21.586043Z",
     "iopub.status.busy": "2024-07-31T15:47:21.585879Z",
     "iopub.status.idle": "2024-07-31T15:47:22.230080Z",
     "shell.execute_reply": "2024-07-31T15:47:22.229505Z",
     "shell.execute_reply.started": "2024-07-31T15:47:21.586021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] 没有那个文件或目录: 'requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **第二步**\n",
    "导入运行所需要的库函数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T15:47:22.231676Z",
     "iopub.status.busy": "2024-07-31T15:47:22.231420Z",
     "iopub.status.idle": "2024-07-31T15:47:23.516377Z",
     "shell.execute_reply": "2024-07-31T15:47:23.515824Z",
     "shell.execute_reply.started": "2024-07-31T15:47:22.231654Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **第三步**\n",
    "数据集路径配置设置\n",
    "- 比赛的数据部分分为**数据特征**和**数据真值**两部分，数据特征是模型训练的**输入**，数据真值是模型训练的**标签**\n",
    "- 其中数据特征部分 输入的路径目录下包含年份文件夹 \n",
    " - 例如示例给出的 \"输入路径/2021/...\" 各年份文件夹下包含从官网下载的压缩包(e.g. weather.round1.train.ft.2021.1.zip) 解压后文件夹下有不同时段的数据文件夹(e.g. 20210101-00), 内部包含6个nc文件, 是从伏羲大模型中获取的从第6小时到第72小时的数据\n",
    "\n",
    "- 数据真值部分 输入的路径目录下包含3个年份的.nc数据, 其中选择哪些年份的特征数据作为输入, 就在years中添加哪些年份\n",
    "- fcst_steps指预测的时间步长, 从第1小时到第72小时, 间隔为1小时\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-31T15:47:23.517459Z",
     "iopub.status.busy": "2024-07-31T15:47:23.517164Z",
     "iopub.status.idle": "2024-07-31T15:47:23.520488Z",
     "shell.execute_reply": "2024-07-31T15:47:23.519954Z",
     "shell.execute_reply.started": "2024-07-31T15:47:23.517439Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path config\n",
    "feature_path = 'feature' #自定义路径并修改为自己的路径\n",
    "gt_path = 'groundtruth' #自定义路径并修改为自己的路径\n",
    "years = ['2021']\n",
    "fcst_steps = list(range(1, 73, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **第四步**\n",
    "Feature类和GroundTruth类是数据集的定义\n",
    "方便后续自定义数据集和数据加载类, 方便我们训练时取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T15:47:23.521487Z",
     "iopub.status.busy": "2024-07-31T15:47:23.521260Z",
     "iopub.status.idle": "2024-07-31T15:47:23.527883Z",
     "shell.execute_reply": "2024-07-31T15:47:23.527407Z",
     "shell.execute_reply.started": "2024-07-31T15:47:23.521468Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature部分\n",
    "class Feature:\n",
    "    def __init__(self):\n",
    "        self.path = feature_path\n",
    "        self.years = years\n",
    "        self.fcst_steps = fcst_steps\n",
    "        self.features_paths_dict = self.get_features_paths()\n",
    "\n",
    "    def get_features_paths(self):\n",
    "        init_time_path_dict = {}\n",
    "        for year in self.years:\n",
    "            init_time_dir_year = os.listdir(os.path.join(self.path, year))\n",
    "            for init_time in sorted(init_time_dir_year):\n",
    "                init_time_path_dict[pd.to_datetime(init_time)] = os.path.join(self.path, year, init_time)\n",
    "        return init_time_path_dict\n",
    "\n",
    "    def get_fts(self, init_time):\n",
    "        return xr.open_mfdataset(self.features_paths_dict.get(init_time) + '/*').sel(lead_time=self.fcst_steps).isel(\n",
    "            time=0)\n",
    "    \n",
    "# GroundTruth部分\n",
    "class GT:\n",
    "    def __init__(self):\n",
    "        self.path = gt_path\n",
    "        self.years = years\n",
    "        self.fcst_steps = fcst_steps\n",
    "        self.gt_paths = [os.path.join(self.path, f'{year}.nc') for year in self.years]\n",
    "        self.gts = xr.open_mfdataset(self.gt_paths)\n",
    "\n",
    "    def parser_gt_timestamps(self, init_time):\n",
    "        return [init_time + pd.Timedelta(f'{fcst_step}h') for fcst_step in self.fcst_steps]\n",
    "\n",
    "    def get_gts(self, init_time):\n",
    "\n",
    "        return self.gts.sel(time=self.parser_gt_timestamps(init_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **第五步**\n",
    "mydataset类的定义, 整合了加载特征和特征对应真值的功能, 方便后续训练时取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T15:47:23.528886Z",
     "iopub.status.busy": "2024-07-31T15:47:23.528595Z",
     "iopub.status.idle": "2024-07-31T15:47:23.533370Z",
     "shell.execute_reply": "2024-07-31T15:47:23.532893Z",
     "shell.execute_reply.started": "2024-07-31T15:47:23.528866Z"
    }
   },
   "outputs": [],
   "source": [
    "# 构建Dataset部分\n",
    "class mydataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.ft = Feature()\n",
    "        self.gt = GT()\n",
    "        self.features_paths_dict = self.ft.features_paths_dict\n",
    "        self.init_times = list(self.features_paths_dict.keys())\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        init_time = self.init_times[index]\n",
    "        try:\n",
    "            ft_item = self.ft.get_fts(init_time).to_array().isel(variable=0).values\n",
    "            gt_item = self.gt.get_gts(init_time).to_array().isel(variable=0).values\n",
    "        except KeyError as e:\n",
    "            print(e)\n",
    "            print(f'init_time: {init_time} not found')\n",
    "            # return None, None\n",
    "            return self.__getitem__(index - 1)\n",
    "        \n",
    "        return ft_item, gt_item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(list(self.init_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **第六步**\n",
    "前五步已经完成了数据预处理加载的相关类和函数的准备, 这里我们可以通过实例化mydataset类来查看数据数量\n",
    "同时完成数据集的构建后, 我们可以通过DataLoader来查看数据集的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T15:47:23.535368Z",
     "iopub.status.busy": "2024-07-31T15:47:23.535083Z",
     "iopub.status.idle": "2024-07-31T15:47:23.858533Z",
     "shell.execute_reply": "2024-07-31T15:47:23.857996Z",
     "shell.execute_reply.started": "2024-07-31T15:47:23.535348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample num: 4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# define dataset\n",
    "my_data = mydataset()\n",
    "print('sample num:', mydataset().__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T15:47:23.859588Z",
     "iopub.status.busy": "2024-07-31T15:47:23.859283Z",
     "iopub.status.idle": "2024-07-31T15:47:23.864087Z",
     "shell.execute_reply": "2024-07-31T15:47:23.863452Z",
     "shell.execute_reply.started": "2024-07-31T15:47:23.859567Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(my_data))\n",
    "val_size = len(my_data) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(my_data, [train_size, val_size])\n",
    "\n",
    "# Create data loaders for training and validation sets\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **第七步**\n",
    "- 完成了数据的准备工作, 接下来就是构建模型的部分\n",
    "- Model这个类, 对我们的模型进行定义, 方便后续训练时调用\n",
    "- 这里我们以一个简单的只有一个卷积层的网络为例\n",
    "- 在本次比赛中, 我们的输入数据维度是(1, 24, 72, W, H), 输出数据维度是(1, 72, W, H) 可以在赛题中查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-31T15:47:23.865490Z",
     "iopub.status.busy": "2024-07-31T15:47:23.865220Z",
     "iopub.status.idle": "2024-07-31T15:47:23.957309Z",
     "shell.execute_reply": "2024-07-31T15:47:23.956742Z",
     "shell.execute_reply.started": "2024-07-31T15:47:23.865462Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#通道注意力机制\n",
    "class TimeAttentionModule(nn.Module):\n",
    "    def __init__(self, channels, heads=1, dropout=0.1):\n",
    "        super(TimeAttentionModule, self).__init__()\n",
    "        self.heads = heads\n",
    "        self.channels = channels\n",
    "\n",
    "        # 为每个头分配通道\n",
    "        self.key_channels = channels // heads\n",
    "        self.query_channels = channels // heads\n",
    "        self.value_channels = channels // heads\n",
    "\n",
    "        # 定义查询（Q）、键（K）、值（V）的线性变换\n",
    "        self.query_layer = nn.Linear(channels, heads * self.query_channels)\n",
    "        self.key_layer = nn.Linear(channels, heads * self.key_channels)\n",
    "        self.value_layer = nn.Linear(channels, heads * self.value_channels)\n",
    "\n",
    "        # 输出层\n",
    "        self.output_layer = nn.Linear(channels, channels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape  # B: 批次大小, T: 时间步长, C: 通道数\n",
    "        x = x.permute(0, 2, 1)  # 调整形状为 (B, C, T)\n",
    "\n",
    "        queries = self.query_layer(x).view(B, self.heads, self.query_channels, T)\n",
    "        keys = self.key_layer(x).view(B, self.heads, self.key_channels, T)\n",
    "        values = self.value_layer(x).view(B, self.heads, self.value_channels, T)\n",
    "\n",
    "        # 计算注意力权重\n",
    "        attention_scores = torch.matmul(queries, keys.transpose(-1, -2)) / math.sqrt(self.key_channels)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=-1)\n",
    "\n",
    "        # 应用注意力权重\n",
    "        output = torch.matmul(attention_weights, values)\n",
    "\n",
    "        # 合并头\n",
    "        output = output.reshape(B, C, T)\n",
    "\n",
    "        # 通过输出层\n",
    "        output = self.output_layer(output)\n",
    "\n",
    "        # 添加残差连接和层归一化\n",
    "        output = self.dropout(self.activation(output + x))\n",
    "\n",
    "        return output\n",
    "#注意力机制\n",
    "class ChannelAttentionModule(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super(ChannelAttentionModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels // reduction_ratio, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_channels // reduction_ratio, in_channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        avg_out = self.fc(self.avg_pool(x).view(b, c))\n",
    "        out = x * avg_out.expand_as(x)\n",
    "        return out\n",
    "# \n",
    "class EnhancedModel(nn.Module):\n",
    "    def __init__(self, num_in_ch, num_out_ch):\n",
    "        super(EnhancedModel, self).__init__()\n",
    "        self.in_channels = num_in_ch\n",
    "        self.conv1 = nn.Conv2d(num_in_ch, 64, kernel_size=3, padding=1)\n",
    "        self.batchnorm = nn.BatchNorm2d(64) \n",
    "        self.attention1 = ChannelAttentionModule(64)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.attention2 = ChannelAttentionModule(64)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, num_out_ch, kernel_size=3, padding=1)\n",
    "        self.time_attention = TimeAttentionModule(64)\n",
    "       \n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, S, C, W, H = tuple(x.shape)\n",
    "        x = x.reshape(B, -1, W, H)\n",
    "        out = self.conv1(x)\n",
    "        out = self.attention1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.attention2(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.time_attention(out)\n",
    "        out = self.activation(out)\n",
    "        out = out.reshape(B, S, W, H)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "# define model\n",
    "in_varibales = 24\n",
    "in_times = len(fcst_steps)\n",
    "out_varibales = 1\n",
    "out_times = len(fcst_steps)\n",
    "input_size = in_times * in_varibales\n",
    "output_size = out_times * out_varibales\n",
    "model = EnhancedModel(input_size, output_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T15:47:23.958819Z",
     "iopub.status.busy": "2024-07-31T15:47:23.958260Z",
     "iopub.status.idle": "2024-07-31T15:47:23.972055Z",
     "shell.execute_reply": "2024-07-31T15:47:23.971588Z",
     "shell.execute_reply.started": "2024-07-31T15:47:23.958785Z"
    }
   },
   "outputs": [],
   "source": [
    "# 推荐先使用这个网络\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class EnhancedModel(nn.Module):\n",
    "    def __init__(self, num_in_ch, num_out_ch):\n",
    "        super(EnhancedModel, self).__init__()\n",
    "        self.conv = nn.Conv2d(num_in_ch, num_out_ch, kernel_size=3, padding=1)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, S, C, W, H = tuple(x.shape)\n",
    "        x = x.reshape(B, -1, W, H)\n",
    "        out = self.conv(x)\n",
    "        out = self.activation(out)\n",
    "        out = out.reshape(B, S, W, H)\n",
    "        return out\n",
    "\n",
    "# define model\n",
    "in_varibales = 24\n",
    "in_times = len(fcst_steps)\n",
    "out_varibales = 1\n",
    "out_times = len(fcst_steps)\n",
    "input_size = in_times * in_varibales\n",
    "output_size = out_times * out_varibales\n",
    "model = EnhancedModel(input_size, output_size).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **第八步**\n",
    "定义模型的损失函数部分， 用于模型训练做反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T15:47:23.973279Z",
     "iopub.status.busy": "2024-07-31T15:47:23.972868Z",
     "iopub.status.idle": "2024-07-31T15:47:23.976173Z",
     "shell.execute_reply": "2024-07-31T15:47:23.975515Z",
     "shell.execute_reply.started": "2024-07-31T15:47:23.973250Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_func = nn.SmoothL1Loss()\n",
    "# loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **第九步**\n",
    "模型训练部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T15:47:23.977448Z",
     "iopub.status.busy": "2024-07-31T15:47:23.977055Z",
     "iopub.status.idle": "2024-07-31T15:47:23.992057Z",
     "shell.execute_reply": "2024-07-31T15:47:23.991547Z",
     "shell.execute_reply.started": "2024-07-31T15:47:23.977420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnhancedModel(\n",
       "  (conv): Conv2d(1728, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型初始化\n",
    "import torch.nn.init as init\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            init.constant_(m.bias, 0)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-31T15:47:23.993332Z",
     "iopub.status.busy": "2024-07-31T15:47:23.992965Z",
     "iopub.status.idle": "2024-07-31T15:50:43.782350Z",
     "shell.execute_reply": "2024-07-31T15:50:43.781758Z",
     "shell.execute_reply.started": "2024-07-31T15:47:23.993304Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/300], Validation Loss: 0.011621\n",
      "[Epoch 2/300], Validation Loss: 0.510049\n",
      "[Epoch 3/300], Validation Loss: 0.213261\n",
      "[Epoch 4/300], Validation Loss: 0.006004\n",
      "[Epoch 5/300], Validation Loss: 0.440476\n",
      "[Epoch 6/300], Validation Loss: 1.064613\n",
      "[Epoch 7/300], Validation Loss: 1.445765\n",
      "[Epoch 8/300], Validation Loss: 1.589299\n",
      "[Epoch 9/300], Validation Loss: 1.945040\n",
      "[Epoch 10/300], Validation Loss: 2.072266\n",
      "[Epoch 11/300], Validation Loss: 2.029991\n",
      "[Epoch 12/300], Validation Loss: 1.829606\n",
      "[Epoch 13/300], Validation Loss: 1.647306\n",
      "[Epoch 14/300], Validation Loss: 1.466165\n",
      "[Epoch 15/300], Validation Loss: 1.512321\n",
      "[Epoch 16/300], Validation Loss: 1.719423\n",
      "[Epoch 17/300], Validation Loss: 1.837920\n",
      "[Epoch 18/300], Validation Loss: 1.896048\n",
      "[Epoch 19/300], Validation Loss: 1.812620\n",
      "[Epoch 20/300], Validation Loss: 1.769122\n",
      "[Epoch 21/300], Validation Loss: 1.720227\n",
      "[Epoch 22/300], Validation Loss: 1.892065\n",
      "[Epoch 23/300], Validation Loss: 1.887482\n",
      "[Epoch 24/300], Validation Loss: 1.792696\n",
      "[Epoch 25/300], Validation Loss: 1.696141\n",
      "[Epoch 26/300], Validation Loss: 1.692496\n",
      "[Epoch 27/300], Validation Loss: 1.758719\n",
      "[Epoch 28/300], Validation Loss: 1.717048\n",
      "[Epoch 29/300], Validation Loss: 1.677503\n",
      "[Epoch 30/300], Validation Loss: 1.592905\n",
      "[Epoch 31/300], Validation Loss: 1.572801\n",
      "[Epoch 32/300], Validation Loss: 1.667182\n",
      "[Epoch 33/300], Validation Loss: 1.532900\n",
      "[Epoch 34/300], Validation Loss: 1.398324\n",
      "[Epoch 35/300], Validation Loss: 1.537672\n",
      "[Epoch 36/300], Validation Loss: 1.469636\n",
      "[Epoch 37/300], Validation Loss: 1.433788\n",
      "[Epoch 38/300], Validation Loss: 1.468906\n",
      "[Epoch 39/300], Validation Loss: 1.406300\n",
      "[Epoch 40/300], Validation Loss: 1.382882\n",
      "[Epoch 41/300], Validation Loss: 1.435550\n",
      "[Epoch 42/300], Validation Loss: 1.445414\n",
      "[Epoch 43/300], Validation Loss: 1.429592\n",
      "[Epoch 44/300], Validation Loss: 1.425513\n",
      "[Epoch 45/300], Validation Loss: 1.432412\n",
      "[Epoch 46/300], Validation Loss: 1.446602\n",
      "[Epoch 47/300], Validation Loss: 1.445543\n",
      "[Epoch 48/300], Validation Loss: 1.415895\n",
      "[Epoch 49/300], Validation Loss: 1.405427\n",
      "[Epoch 50/300], Validation Loss: 1.426218\n",
      "[Epoch 51/300], Validation Loss: 1.475799\n",
      "[Epoch 52/300], Validation Loss: 1.390669\n",
      "[Epoch 53/300], Validation Loss: 1.380521\n",
      "[Epoch 54/300], Validation Loss: 1.444225\n",
      "[Epoch 55/300], Validation Loss: 1.419910\n",
      "[Epoch 56/300], Validation Loss: 1.384482\n",
      "[Epoch 57/300], Validation Loss: 1.388352\n",
      "[Epoch 58/300], Validation Loss: 1.410716\n",
      "[Epoch 59/300], Validation Loss: 1.364134\n",
      "[Epoch 60/300], Validation Loss: 1.337790\n",
      "[Epoch 61/300], Validation Loss: 1.377407\n",
      "[Epoch 62/300], Validation Loss: 1.354607\n",
      "[Epoch 63/300], Validation Loss: 1.334234\n",
      "[Epoch 64/300], Validation Loss: 1.326237\n",
      "[Epoch 65/300], Validation Loss: 1.328394\n",
      "[Epoch 66/300], Validation Loss: 1.303960\n",
      "[Epoch 67/300], Validation Loss: 1.296561\n",
      "[Epoch 68/300], Validation Loss: 1.268634\n",
      "[Epoch 69/300], Validation Loss: 1.282659\n",
      "[Epoch 70/300], Validation Loss: 1.253890\n",
      "[Epoch 71/300], Validation Loss: 1.221473\n",
      "[Epoch 72/300], Validation Loss: 1.245905\n",
      "[Epoch 73/300], Validation Loss: 1.210897\n",
      "[Epoch 74/300], Validation Loss: 1.200761\n",
      "[Epoch 75/300], Validation Loss: 1.188430\n",
      "[Epoch 76/300], Validation Loss: 1.198078\n",
      "[Epoch 77/300], Validation Loss: 1.158744\n",
      "[Epoch 78/300], Validation Loss: 1.167350\n",
      "[Epoch 79/300], Validation Loss: 1.164384\n",
      "[Epoch 80/300], Validation Loss: 1.140233\n",
      "[Epoch 81/300], Validation Loss: 1.134774\n",
      "[Epoch 82/300], Validation Loss: 1.128420\n",
      "[Epoch 83/300], Validation Loss: 1.116720\n",
      "[Epoch 84/300], Validation Loss: 1.111961\n",
      "[Epoch 85/300], Validation Loss: 1.092060\n",
      "[Epoch 86/300], Validation Loss: 1.093861\n",
      "[Epoch 87/300], Validation Loss: 1.098827\n",
      "[Epoch 88/300], Validation Loss: 1.053665\n",
      "[Epoch 89/300], Validation Loss: 1.083385\n",
      "[Epoch 90/300], Validation Loss: 1.057514\n",
      "[Epoch 91/300], Validation Loss: 1.027654\n",
      "[Epoch 92/300], Validation Loss: 1.077570\n",
      "[Epoch 93/300], Validation Loss: 1.020676\n",
      "[Epoch 94/300], Validation Loss: 1.016056\n",
      "[Epoch 95/300], Validation Loss: 1.025181\n",
      "[Epoch 96/300], Validation Loss: 1.028200\n",
      "[Epoch 97/300], Validation Loss: 0.996651\n",
      "[Epoch 98/300], Validation Loss: 1.023041\n",
      "[Epoch 99/300], Validation Loss: 1.007737\n",
      "[Epoch 100/300], Validation Loss: 1.002503\n",
      "[Epoch 101/300], Validation Loss: 1.006595\n",
      "[Epoch 102/300], Validation Loss: 1.010118\n",
      "[Epoch 103/300], Validation Loss: 0.984382\n",
      "[Epoch 104/300], Validation Loss: 0.983211\n",
      "[Epoch 105/300], Validation Loss: 0.995635\n",
      "[Epoch 106/300], Validation Loss: 0.973214\n",
      "[Epoch 107/300], Validation Loss: 0.955298\n",
      "[Epoch 108/300], Validation Loss: 0.972756\n",
      "[Epoch 109/300], Validation Loss: 0.989261\n",
      "[Epoch 110/300], Validation Loss: 0.970822\n",
      "[Epoch 111/300], Validation Loss: 0.968568\n",
      "[Epoch 112/300], Validation Loss: 0.978908\n",
      "[Epoch 113/300], Validation Loss: 0.975557\n",
      "[Epoch 114/300], Validation Loss: 0.959834\n",
      "[Epoch 115/300], Validation Loss: 0.971588\n",
      "[Epoch 116/300], Validation Loss: 0.979725\n",
      "[Epoch 117/300], Validation Loss: 0.949378\n",
      "[Epoch 118/300], Validation Loss: 0.964257\n",
      "[Epoch 119/300], Validation Loss: 0.973217\n",
      "[Epoch 120/300], Validation Loss: 0.953344\n",
      "[Epoch 121/300], Validation Loss: 0.953875\n",
      "[Epoch 122/300], Validation Loss: 0.972494\n",
      "[Epoch 123/300], Validation Loss: 0.958159\n",
      "[Epoch 124/300], Validation Loss: 0.946283\n",
      "[Epoch 125/300], Validation Loss: 0.964180\n",
      "[Epoch 126/300], Validation Loss: 0.962334\n",
      "[Epoch 127/300], Validation Loss: 0.954071\n",
      "[Epoch 128/300], Validation Loss: 0.955675\n",
      "[Epoch 129/300], Validation Loss: 0.963248\n",
      "[Epoch 130/300], Validation Loss: 0.960192\n",
      "[Epoch 131/300], Validation Loss: 0.949393\n",
      "[Epoch 132/300], Validation Loss: 0.948131\n",
      "[Epoch 133/300], Validation Loss: 0.951151\n",
      "[Epoch 134/300], Validation Loss: 0.956435\n",
      "[Epoch 135/300], Validation Loss: 0.977594\n",
      "[Epoch 136/300], Validation Loss: 0.908570\n",
      "[Epoch 137/300], Validation Loss: 0.969873\n",
      "[Epoch 138/300], Validation Loss: 0.973619\n",
      "[Epoch 139/300], Validation Loss: 0.870299\n",
      "[Epoch 140/300], Validation Loss: 0.981853\n",
      "[Epoch 141/300], Validation Loss: 0.977556\n",
      "[Epoch 142/300], Validation Loss: 0.895109\n",
      "[Epoch 143/300], Validation Loss: 0.960440\n",
      "[Epoch 144/300], Validation Loss: 0.946090\n",
      "[Epoch 145/300], Validation Loss: 0.937774\n",
      "[Epoch 146/300], Validation Loss: 0.944398\n",
      "[Epoch 147/300], Validation Loss: 0.936547\n",
      "[Epoch 148/300], Validation Loss: 0.959311\n",
      "[Epoch 149/300], Validation Loss: 0.934666\n",
      "[Epoch 150/300], Validation Loss: 0.939616\n",
      "[Epoch 151/300], Validation Loss: 0.969977\n",
      "[Epoch 152/300], Validation Loss: 0.936485\n",
      "[Epoch 153/300], Validation Loss: 0.977335\n",
      "[Epoch 154/300], Validation Loss: 0.934200\n",
      "[Epoch 155/300], Validation Loss: 0.910592\n",
      "[Epoch 156/300], Validation Loss: 0.953585\n",
      "[Epoch 157/300], Validation Loss: 0.882165\n",
      "[Epoch 158/300], Validation Loss: 0.882813\n",
      "[Epoch 159/300], Validation Loss: 0.969278\n",
      "[Epoch 160/300], Validation Loss: 0.942066\n",
      "[Epoch 161/300], Validation Loss: 0.991754\n",
      "[Epoch 162/300], Validation Loss: 0.930087\n",
      "[Epoch 163/300], Validation Loss: 0.919870\n",
      "[Epoch 164/300], Validation Loss: 0.941206\n",
      "[Epoch 165/300], Validation Loss: 0.857290\n",
      "[Epoch 166/300], Validation Loss: 0.912130\n",
      "[Epoch 167/300], Validation Loss: 0.949644\n",
      "[Epoch 168/300], Validation Loss: 0.876950\n",
      "[Epoch 169/300], Validation Loss: 0.933444\n",
      "[Epoch 170/300], Validation Loss: 0.964532\n",
      "[Epoch 171/300], Validation Loss: 0.899306\n",
      "[Epoch 172/300], Validation Loss: 0.966985\n",
      "[Epoch 173/300], Validation Loss: 0.884032\n",
      "[Epoch 174/300], Validation Loss: 0.871964\n",
      "[Epoch 175/300], Validation Loss: 0.966023\n",
      "[Epoch 176/300], Validation Loss: 0.897691\n",
      "[Epoch 177/300], Validation Loss: 0.960727\n",
      "[Epoch 178/300], Validation Loss: 0.907563\n",
      "[Epoch 179/300], Validation Loss: 0.894177\n",
      "[Epoch 180/300], Validation Loss: 0.954677\n",
      "[Epoch 181/300], Validation Loss: 0.937917\n",
      "[Epoch 182/300], Validation Loss: 0.918898\n",
      "[Epoch 183/300], Validation Loss: 0.991616\n",
      "[Epoch 184/300], Validation Loss: 0.856393\n",
      "[Epoch 185/300], Validation Loss: 0.889527\n",
      "[Epoch 186/300], Validation Loss: 0.939347\n",
      "[Epoch 187/300], Validation Loss: 0.883817\n",
      "[Epoch 188/300], Validation Loss: 0.904444\n",
      "[Epoch 189/300], Validation Loss: 0.954879\n",
      "[Epoch 190/300], Validation Loss: 0.907387\n",
      "[Epoch 191/300], Validation Loss: 0.981396\n",
      "[Epoch 192/300], Validation Loss: 0.891269\n",
      "[Epoch 193/300], Validation Loss: 0.854186\n",
      "[Epoch 194/300], Validation Loss: 0.923639\n",
      "[Epoch 195/300], Validation Loss: 0.935623\n",
      "[Epoch 196/300], Validation Loss: 0.885586\n",
      "[Epoch 197/300], Validation Loss: 0.942609\n",
      "[Epoch 198/300], Validation Loss: 0.910490\n",
      "[Epoch 199/300], Validation Loss: 0.936694\n",
      "[Epoch 200/300], Validation Loss: 0.885866\n",
      "[Epoch 201/300], Validation Loss: 0.864293\n",
      "[Epoch 202/300], Validation Loss: 0.920704\n",
      "[Epoch 203/300], Validation Loss: 0.818988\n",
      "[Epoch 204/300], Validation Loss: 0.898873\n",
      "[Epoch 205/300], Validation Loss: 1.004615\n",
      "[Epoch 206/300], Validation Loss: 0.853318\n",
      "[Epoch 207/300], Validation Loss: 0.967020\n",
      "[Epoch 208/300], Validation Loss: 0.955184\n",
      "[Epoch 209/300], Validation Loss: 0.808867\n",
      "[Epoch 210/300], Validation Loss: 0.961390\n",
      "[Epoch 211/300], Validation Loss: 0.928973\n",
      "[Epoch 212/300], Validation Loss: 0.888594\n",
      "[Epoch 213/300], Validation Loss: 0.953859\n",
      "[Epoch 214/300], Validation Loss: 0.843364\n",
      "[Epoch 215/300], Validation Loss: 0.882410\n",
      "[Epoch 216/300], Validation Loss: 0.990085\n",
      "[Epoch 217/300], Validation Loss: 0.826078\n",
      "[Epoch 218/300], Validation Loss: 0.972171\n",
      "[Epoch 219/300], Validation Loss: 0.949383\n",
      "[Epoch 220/300], Validation Loss: 0.809850\n",
      "[Epoch 221/300], Validation Loss: 0.927433\n",
      "[Epoch 222/300], Validation Loss: 0.956446\n",
      "[Epoch 223/300], Validation Loss: 0.844551\n",
      "[Epoch 224/300], Validation Loss: 1.009080\n",
      "[Epoch 225/300], Validation Loss: 0.888196\n",
      "[Epoch 226/300], Validation Loss: 0.857687\n",
      "[Epoch 227/300], Validation Loss: 0.974851\n",
      "[Epoch 228/300], Validation Loss: 0.857166\n",
      "[Epoch 229/300], Validation Loss: 0.950727\n",
      "[Epoch 230/300], Validation Loss: 0.943793\n",
      "[Epoch 231/300], Validation Loss: 0.776821\n",
      "[Epoch 232/300], Validation Loss: 0.984579\n",
      "[Epoch 233/300], Validation Loss: 0.932148\n",
      "[Epoch 234/300], Validation Loss: 0.885027\n",
      "[Epoch 235/300], Validation Loss: 0.987621\n",
      "[Epoch 236/300], Validation Loss: 0.915959\n",
      "[Epoch 237/300], Validation Loss: 0.922762\n",
      "[Epoch 238/300], Validation Loss: 0.972334\n",
      "[Epoch 239/300], Validation Loss: 0.891692\n",
      "[Epoch 240/300], Validation Loss: 0.933673\n",
      "[Epoch 241/300], Validation Loss: 0.917844\n",
      "[Epoch 242/300], Validation Loss: 0.866652\n",
      "[Epoch 243/300], Validation Loss: 0.920671\n",
      "[Epoch 244/300], Validation Loss: 0.920267\n",
      "[Epoch 245/300], Validation Loss: 0.882294\n",
      "[Epoch 246/300], Validation Loss: 0.928073\n",
      "[Epoch 247/300], Validation Loss: 0.892038\n",
      "[Epoch 248/300], Validation Loss: 0.907631\n",
      "[Epoch 249/300], Validation Loss: 0.907338\n",
      "[Epoch 250/300], Validation Loss: 0.879284\n",
      "[Epoch 251/300], Validation Loss: 0.914336\n",
      "[Epoch 252/300], Validation Loss: 0.847982\n",
      "[Epoch 253/300], Validation Loss: 0.874444\n",
      "[Epoch 254/300], Validation Loss: 0.885525\n",
      "[Epoch 255/300], Validation Loss: 0.847163\n",
      "[Epoch 256/300], Validation Loss: 0.882398\n",
      "[Epoch 257/300], Validation Loss: 0.863335\n",
      "[Epoch 258/300], Validation Loss: 0.872509\n",
      "[Epoch 259/300], Validation Loss: 0.850822\n",
      "[Epoch 260/300], Validation Loss: 0.848449\n",
      "[Epoch 261/300], Validation Loss: 0.858526\n",
      "[Epoch 262/300], Validation Loss: 0.836171\n",
      "[Epoch 263/300], Validation Loss: 0.804240\n",
      "[Epoch 264/300], Validation Loss: 0.838057\n",
      "[Epoch 265/300], Validation Loss: 0.836560\n",
      "[Epoch 266/300], Validation Loss: 0.838134\n",
      "[Epoch 267/300], Validation Loss: 0.830072\n",
      "[Epoch 268/300], Validation Loss: 0.824257\n",
      "[Epoch 269/300], Validation Loss: 0.813689\n",
      "[Epoch 270/300], Validation Loss: 0.807086\n",
      "[Epoch 271/300], Validation Loss: 0.807754\n",
      "[Epoch 272/300], Validation Loss: 0.802844\n",
      "[Epoch 273/300], Validation Loss: 0.796414\n",
      "[Epoch 274/300], Validation Loss: 0.793270\n",
      "[Epoch 275/300], Validation Loss: 0.791787\n",
      "[Epoch 276/300], Validation Loss: 0.785301\n",
      "[Epoch 277/300], Validation Loss: 0.778456\n",
      "[Epoch 278/300], Validation Loss: 0.781163\n",
      "[Epoch 279/300], Validation Loss: 0.774072\n",
      "[Epoch 280/300], Validation Loss: 0.763469\n",
      "[Epoch 281/300], Validation Loss: 0.762108\n",
      "[Epoch 282/300], Validation Loss: 0.758644\n",
      "[Epoch 283/300], Validation Loss: 0.750959\n",
      "[Epoch 284/300], Validation Loss: 0.743355\n",
      "[Epoch 285/300], Validation Loss: 0.738512\n",
      "[Epoch 286/300], Validation Loss: 0.738082\n",
      "[Epoch 287/300], Validation Loss: 0.730096\n",
      "[Epoch 288/300], Validation Loss: 0.732503\n",
      "[Epoch 289/300], Validation Loss: 0.732098\n",
      "[Epoch 290/300], Validation Loss: 0.725467\n",
      "[Epoch 291/300], Validation Loss: 0.708294\n",
      "[Epoch 292/300], Validation Loss: 0.704974\n",
      "[Epoch 293/300], Validation Loss: 0.707872\n",
      "[Epoch 294/300], Validation Loss: 0.703557\n",
      "[Epoch 295/300], Validation Loss: 0.692914\n",
      "[Epoch 296/300], Validation Loss: 0.684453\n",
      "[Epoch 297/300], Validation Loss: 0.687441\n",
      "[Epoch 298/300], Validation Loss: 0.692087\n",
      "[Epoch 299/300], Validation Loss: 0.680865\n",
      "[Epoch 300/300], Validation Loss: 0.672275\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# from tqdm import tqdm\n",
    "# Train the model\n",
    "num_epochs = 300\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0004, weight_decay=1e-6)\n",
    "\n",
    "# for epoch in tqdm(range(num_epochs)):\n",
    "os.makedirs('./model', exist_ok=True)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    loss = 0.0\n",
    "    for index, (ft_item, gt_item) in enumerate(train_loader):\n",
    "        ft_item = ft_item.cuda().float()\n",
    "        gt_item = gt_item.cuda().float()\n",
    "        # print(\"gt\", gt_item.max(), gt_item.min())\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        output_item = model(ft_item)\n",
    "        # print(output_item.max(), output_item.min())\n",
    "        loss = loss_func(output_item, gt_item)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        loss += loss.item()\n",
    "        # Print the loss for every 10 steps\n",
    "        if (index+1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{index+1}/{len(train_loader)}], Loss: {loss.item():.6f}\")\n",
    "            loss = 0.0\n",
    "    # Save the model weights\n",
    "    torch.save(model.state_dict(), f'./model/model_weights_{epoch}.pth')\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for index, (ft_item, gt_item) in enumerate(val_loader):\n",
    "            ft_item = ft_item.cuda().float()\n",
    "            gt_item = gt_item.cuda().float()\n",
    "            output_item = model(ft_item)\n",
    "            val_loss = loss_func(output_item.max(), gt_item.max())\n",
    "            val_loss += val_loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f\"[Epoch {epoch+1}/{num_epochs}], Validation Loss: {val_loss:.6f}\")\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **第十步**\n",
    "- 模型推理部分, 通过加载模型使用测试数据作为输入, 得到预测结果\n",
    "- 其中test_data_path需要给出从下载测试数据解压后的目录路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-07-31T15:53:07.535203Z",
     "iopub.status.busy": "2024-07-31T15:53:07.534843Z",
     "iopub.status.idle": "2024-07-31T15:53:10.922424Z",
     "shell.execute_reply": "2024-07-31T15:53:10.921708Z",
     "shell.execute_reply.started": "2024-07-31T15:53:07.535179Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape for sample 122: torch.Size([1, 72, 57, 81]), True\n",
      "122: max: 38.71875, min: 0.0\n",
      "Output shape for sample 228: torch.Size([1, 72, 57, 81]), True\n",
      "228: max: 11.359375, min: 0.0\n",
      "Output shape for sample 226: torch.Size([1, 72, 57, 81]), True\n",
      "226: max: 13.1796875, min: 0.0\n",
      "Output shape for sample 227: torch.Size([1, 72, 57, 81]), True\n",
      "227: max: 29.84375, min: 0.0\n",
      "Output shape for sample 054: torch.Size([1, 72, 57, 81]), True\n",
      "054: max: 35.59375, min: 0.0\n",
      "Output shape for sample 176: torch.Size([1, 72, 57, 81]), True\n",
      "176: max: 10.375, min: 0.0\n",
      "Output shape for sample 058: torch.Size([1, 72, 57, 81]), True\n",
      "058: max: 10.71875, min: 0.0\n",
      "Output shape for sample 183: torch.Size([1, 72, 57, 81]), True\n",
      "183: max: 37.6875, min: 0.0\n",
      "Output shape for sample 222: torch.Size([1, 72, 57, 81]), True\n",
      "222: max: 15.5859375, min: 0.0\n",
      "Output shape for sample 299: torch.Size([1, 72, 57, 81]), True\n",
      "299: max: 12.0078125, min: 0.0\n",
      "Output shape for sample 042: torch.Size([1, 72, 57, 81]), True\n",
      "042: max: 3.279296875, min: 0.0\n",
      "Output shape for sample 012: torch.Size([1, 72, 57, 81]), True\n",
      "012: max: 30.3125, min: 0.0\n",
      "Output shape for sample 006: torch.Size([1, 72, 57, 81]), True\n",
      "006: max: 31.421875, min: 0.0\n",
      "Output shape for sample 194: torch.Size([1, 72, 57, 81]), True\n",
      "194: max: 35.84375, min: 0.401123046875\n",
      "Output shape for sample 069: torch.Size([1, 72, 57, 81]), True\n",
      "069: max: 13.265625, min: 0.0\n",
      "Output shape for sample 143: torch.Size([1, 72, 57, 81]), True\n",
      "143: max: 47.21875, min: 0.0\n",
      "Output shape for sample 133: torch.Size([1, 72, 57, 81]), True\n",
      "133: max: 14.59375, min: 0.0\n",
      "Output shape for sample 163: torch.Size([1, 72, 57, 81]), True\n",
      "163: max: 37.5625, min: 0.0\n",
      "Output shape for sample 118: torch.Size([1, 72, 57, 81]), True\n",
      "118: max: 9.375, min: 0.0\n",
      "Output shape for sample 000: torch.Size([1, 72, 57, 81]), True\n",
      "000: max: 5.2890625, min: 0.0\n",
      "Output shape for sample 063: torch.Size([1, 72, 57, 81]), True\n",
      "063: max: 41.8125, min: 0.0\n",
      "Output shape for sample 264: torch.Size([1, 72, 57, 81]), True\n",
      "264: max: 30.328125, min: 0.0\n",
      "Output shape for sample 186: torch.Size([1, 72, 57, 81]), True\n",
      "186: max: 24.59375, min: 0.0\n",
      "Output shape for sample 266: torch.Size([1, 72, 57, 81]), True\n",
      "266: max: 11.7109375, min: 0.0\n",
      "Output shape for sample 051: torch.Size([1, 72, 57, 81]), True\n",
      "051: max: 18.859375, min: 0.0\n",
      "Output shape for sample 247: torch.Size([1, 72, 57, 81]), True\n",
      "247: max: 11.5546875, min: 0.0\n",
      "Output shape for sample 073: torch.Size([1, 72, 57, 81]), True\n",
      "073: max: 19.8125, min: 0.0\n",
      "Output shape for sample 107: torch.Size([1, 72, 57, 81]), True\n",
      "107: max: 36.21875, min: 0.0\n",
      "Output shape for sample 062: torch.Size([1, 72, 57, 81]), True\n",
      "062: max: 5.625, min: 0.0\n",
      "Output shape for sample 034: torch.Size([1, 72, 57, 81]), True\n",
      "034: max: 40.09375, min: 0.0\n",
      "Output shape for sample 261: torch.Size([1, 72, 57, 81]), True\n",
      "261: max: 8.546875, min: 0.0\n",
      "Output shape for sample 068: torch.Size([1, 72, 57, 81]), True\n",
      "068: max: 23.78125, min: 0.0\n",
      "Output shape for sample 211: torch.Size([1, 72, 57, 81]), True\n",
      "211: max: 24.875, min: 0.0\n",
      "Output shape for sample 245: torch.Size([1, 72, 57, 81]), True\n",
      "245: max: 33.8125, min: 0.0\n",
      "Output shape for sample 150: torch.Size([1, 72, 57, 81]), True\n",
      "150: max: 22.03125, min: 0.0\n",
      "Output shape for sample 071: torch.Size([1, 72, 57, 81]), True\n",
      "071: max: 2.24609375, min: 0.0\n",
      "Output shape for sample 078: torch.Size([1, 72, 57, 81]), True\n",
      "078: max: 57.21875, min: 0.0\n",
      "Output shape for sample 175: torch.Size([1, 72, 57, 81]), True\n",
      "175: max: 30.125, min: 0.0\n",
      "Output shape for sample 242: torch.Size([1, 72, 57, 81]), True\n",
      "242: max: 4.375, min: 0.0\n",
      "Output shape for sample 223: torch.Size([1, 72, 57, 81]), True\n",
      "223: max: 3.052734375, min: 0.0\n",
      "Output shape for sample 151: torch.Size([1, 72, 57, 81]), True\n",
      "151: max: 39.78125, min: 0.0\n",
      "Output shape for sample 156: torch.Size([1, 72, 57, 81]), True\n",
      "156: max: 11.59375, min: 0.0\n",
      "Output shape for sample 082: torch.Size([1, 72, 57, 81]), True\n",
      "082: max: 14.2421875, min: 0.0\n",
      "Output shape for sample 231: torch.Size([1, 72, 57, 81]), True\n",
      "231: max: 19.734375, min: 0.0\n",
      "Output shape for sample 179: torch.Size([1, 72, 57, 81]), True\n",
      "179: max: 13.234375, min: 0.0\n",
      "Output shape for sample 275: torch.Size([1, 72, 57, 81]), True\n",
      "275: max: 30.359375, min: 0.0\n",
      "Output shape for sample 096: torch.Size([1, 72, 57, 81]), True\n",
      "096: max: 34.0, min: 0.0\n",
      "Output shape for sample 149: torch.Size([1, 72, 57, 81]), True\n",
      "149: max: 34.0, min: 0.0\n",
      "Output shape for sample 159: torch.Size([1, 72, 57, 81]), True\n",
      "159: max: 9.890625, min: 0.0\n",
      "Output shape for sample 102: torch.Size([1, 72, 57, 81]), True\n",
      "102: max: 11.015625, min: 0.0\n",
      "Output shape for sample 215: torch.Size([1, 72, 57, 81]), True\n",
      "215: max: 37.90625, min: 0.0\n",
      "Output shape for sample 201: torch.Size([1, 72, 57, 81]), True\n",
      "201: max: 6.1015625, min: 0.0\n",
      "Output shape for sample 003: torch.Size([1, 72, 57, 81]), True\n",
      "003: max: 7.73046875, min: 0.0\n",
      "Output shape for sample 099: torch.Size([1, 72, 57, 81]), True\n",
      "099: max: 4.875, min: 0.0\n",
      "Output shape for sample 281: torch.Size([1, 72, 57, 81]), True\n",
      "281: max: 29.875, min: 0.0\n",
      "Output shape for sample 273: torch.Size([1, 72, 57, 81]), True\n",
      "273: max: 38.78125, min: 0.21630859375\n",
      "Output shape for sample 286: torch.Size([1, 72, 57, 81]), True\n",
      "286: max: 34.625, min: 0.0\n",
      "Output shape for sample 046: torch.Size([1, 72, 57, 81]), True\n",
      "046: max: 43.21875, min: 0.0\n",
      "Output shape for sample 218: torch.Size([1, 72, 57, 81]), True\n",
      "218: max: 1.798828125, min: 0.0\n",
      "Output shape for sample 144: torch.Size([1, 72, 57, 81]), True\n",
      "144: max: 8.5703125, min: 0.0\n",
      "Output shape for sample 171: torch.Size([1, 72, 57, 81]), True\n",
      "171: max: 49.1875, min: 0.0\n",
      "Output shape for sample 101: torch.Size([1, 72, 57, 81]), True\n",
      "101: max: 20.3125, min: 0.0\n",
      "Output shape for sample 208: torch.Size([1, 72, 57, 81]), True\n",
      "208: max: 37.78125, min: 0.0\n",
      "Output shape for sample 185: torch.Size([1, 72, 57, 81]), True\n",
      "185: max: 7.62890625, min: 0.0\n",
      "Output shape for sample 287: torch.Size([1, 72, 57, 81]), True\n",
      "287: max: 7.35546875, min: 0.0\n",
      "Output shape for sample 207: torch.Size([1, 72, 57, 81]), True\n",
      "207: max: 26.359375, min: 0.0\n",
      "Output shape for sample 114: torch.Size([1, 72, 57, 81]), True\n",
      "114: max: 39.875, min: 0.0\n",
      "Output shape for sample 162: torch.Size([1, 72, 57, 81]), True\n",
      "162: max: 34.75, min: 0.0\n",
      "Output shape for sample 016: torch.Size([1, 72, 57, 81]), True\n",
      "016: max: 41.40625, min: 0.0\n",
      "Output shape for sample 219: torch.Size([1, 72, 57, 81]), True\n",
      "219: max: 33.8125, min: 0.0\n",
      "Output shape for sample 086: torch.Size([1, 72, 57, 81]), True\n",
      "086: max: 47.3125, min: 0.0\n",
      "Output shape for sample 278: torch.Size([1, 72, 57, 81]), True\n",
      "278: max: 14.375, min: 0.0\n",
      "Output shape for sample 214: torch.Size([1, 72, 57, 81]), True\n",
      "214: max: 34.15625, min: 0.0\n",
      "Output shape for sample 093: torch.Size([1, 72, 57, 81]), True\n",
      "093: max: 6.234375, min: 0.0\n",
      "Output shape for sample 085: torch.Size([1, 72, 57, 81]), True\n",
      "085: max: 4.92578125, min: 0.0\n",
      "Output shape for sample 091: torch.Size([1, 72, 57, 81]), True\n",
      "091: max: 32.09375, min: 0.0\n",
      "Output shape for sample 166: torch.Size([1, 72, 57, 81]), True\n",
      "166: max: 35.03125, min: 0.0\n",
      "Output shape for sample 031: torch.Size([1, 72, 57, 81]), True\n",
      "031: max: 21.296875, min: 0.0\n",
      "Output shape for sample 116: torch.Size([1, 72, 57, 81]), True\n",
      "116: max: 30.96875, min: 0.0\n",
      "Output shape for sample 204: torch.Size([1, 72, 57, 81]), True\n",
      "204: max: 2.9140625, min: 0.0\n",
      "Output shape for sample 124: torch.Size([1, 72, 57, 81]), True\n",
      "124: max: 2.353515625, min: 0.0\n",
      "Output shape for sample 297: torch.Size([1, 72, 57, 81]), True\n",
      "297: max: 11.8046875, min: 0.0\n",
      "Output shape for sample 076: torch.Size([1, 72, 57, 81]), True\n",
      "076: max: 19.25, min: 0.0\n",
      "Output shape for sample 032: torch.Size([1, 72, 57, 81]), True\n",
      "032: max: 7.046875, min: 0.0\n",
      "Output shape for sample 170: torch.Size([1, 72, 57, 81]), True\n",
      "170: max: 22.703125, min: 0.0\n",
      "Output shape for sample 030: torch.Size([1, 72, 57, 81]), True\n",
      "030: max: 13.4453125, min: 0.0\n",
      "Output shape for sample 045: torch.Size([1, 72, 57, 81]), True\n",
      "045: max: 16.015625, min: 0.0\n",
      "Output shape for sample 039: torch.Size([1, 72, 57, 81]), True\n",
      "039: max: 7.0234375, min: 0.0\n",
      "Output shape for sample 083: torch.Size([1, 72, 57, 81]), True\n",
      "083: max: 9.4609375, min: 0.0\n",
      "Output shape for sample 132: torch.Size([1, 72, 57, 81]), True\n",
      "132: max: 5.91015625, min: 0.0\n",
      "Output shape for sample 256: torch.Size([1, 72, 57, 81]), True\n",
      "256: max: 11.53125, min: 0.0\n",
      "Output shape for sample 187: torch.Size([1, 72, 57, 81]), True\n",
      "187: max: 14.4140625, min: 0.0\n",
      "Output shape for sample 044: torch.Size([1, 72, 57, 81]), True\n",
      "044: max: 12.6796875, min: 0.0\n",
      "Output shape for sample 239: torch.Size([1, 72, 57, 81]), True\n",
      "239: max: 37.0625, min: 0.0\n",
      "Output shape for sample 075: torch.Size([1, 72, 57, 81]), True\n",
      "075: max: 35.09375, min: 0.0\n",
      "Output shape for sample 088: torch.Size([1, 72, 57, 81]), True\n",
      "088: max: 40.625, min: 0.0\n",
      "Output shape for sample 224: torch.Size([1, 72, 57, 81]), True\n",
      "224: max: 24.46875, min: 0.0\n",
      "Output shape for sample 205: torch.Size([1, 72, 57, 81]), True\n",
      "205: max: 11.5546875, min: 0.0\n",
      "Output shape for sample 236: torch.Size([1, 72, 57, 81]), True\n",
      "236: max: 59.53125, min: 0.0\n",
      "Output shape for sample 120: torch.Size([1, 72, 57, 81]), True\n",
      "120: max: 35.53125, min: 0.0\n",
      "Output shape for sample 097: torch.Size([1, 72, 57, 81]), True\n",
      "097: max: 42.78125, min: 0.0\n",
      "Output shape for sample 291: torch.Size([1, 72, 57, 81]), True\n",
      "291: max: 5.37109375, min: 0.0\n",
      "Output shape for sample 019: torch.Size([1, 72, 57, 81]), True\n",
      "019: max: 3.189453125, min: 0.0\n",
      "Output shape for sample 249: torch.Size([1, 72, 57, 81]), True\n",
      "249: max: 3.513671875, min: 0.0\n",
      "Output shape for sample 009: torch.Size([1, 72, 57, 81]), True\n",
      "009: max: 20.78125, min: 0.0\n",
      "Output shape for sample 121: torch.Size([1, 72, 57, 81]), True\n",
      "121: max: 18.890625, min: 0.0\n",
      "Output shape for sample 241: torch.Size([1, 72, 57, 81]), True\n",
      "241: max: 56.375, min: 0.0\n",
      "Output shape for sample 038: torch.Size([1, 72, 57, 81]), True\n",
      "038: max: 33.375, min: 0.0\n",
      "Output shape for sample 203: torch.Size([1, 72, 57, 81]), True\n",
      "203: max: 9.7421875, min: 0.0\n",
      "Output shape for sample 270: torch.Size([1, 72, 57, 81]), True\n",
      "270: max: 12.546875, min: 0.0\n",
      "Output shape for sample 268: torch.Size([1, 72, 57, 81]), True\n",
      "268: max: 7.30078125, min: 0.0\n",
      "Output shape for sample 277: torch.Size([1, 72, 57, 81]), True\n",
      "277: max: 60.96875, min: 0.0\n",
      "Output shape for sample 027: torch.Size([1, 72, 57, 81]), True\n",
      "027: max: 8.671875, min: 0.0\n",
      "Output shape for sample 206: torch.Size([1, 72, 57, 81]), True\n",
      "206: max: 40.75, min: 0.0\n",
      "Output shape for sample 246: torch.Size([1, 72, 57, 81]), True\n",
      "246: max: 11.7578125, min: 0.0\n",
      "Output shape for sample 265: torch.Size([1, 72, 57, 81]), True\n",
      "265: max: 36.4375, min: 0.47900390625\n",
      "Output shape for sample 103: torch.Size([1, 72, 57, 81]), True\n",
      "103: max: 4.12109375, min: 0.0\n",
      "Output shape for sample 263: torch.Size([1, 72, 57, 81]), True\n",
      "263: max: 6.09765625, min: 0.0\n",
      "Output shape for sample 180: torch.Size([1, 72, 57, 81]), True\n",
      "180: max: 11.875, min: 0.0\n",
      "Output shape for sample 112: torch.Size([1, 72, 57, 81]), True\n",
      "112: max: 8.3515625, min: 0.0\n",
      "Output shape for sample 130: torch.Size([1, 72, 57, 81]), True\n",
      "130: max: 14.8203125, min: 0.0\n",
      "Output shape for sample 138: torch.Size([1, 72, 57, 81]), True\n",
      "138: max: 2.017578125, min: 0.0\n",
      "Output shape for sample 057: torch.Size([1, 72, 57, 81]), True\n",
      "057: max: 34.46875, min: 0.0\n",
      "Output shape for sample 148: torch.Size([1, 72, 57, 81]), True\n",
      "148: max: 19.078125, min: 0.0\n",
      "Output shape for sample 072: torch.Size([1, 72, 57, 81]), True\n",
      "072: max: 16.921875, min: 0.0\n",
      "Output shape for sample 177: torch.Size([1, 72, 57, 81]), True\n",
      "177: max: 44.875, min: 0.1551513671875\n",
      "Output shape for sample 280: torch.Size([1, 72, 57, 81]), True\n",
      "280: max: 37.375, min: 0.0\n",
      "Output shape for sample 289: torch.Size([1, 72, 57, 81]), True\n",
      "289: max: 12.59375, min: 0.0\n",
      "Output shape for sample 196: torch.Size([1, 72, 57, 81]), True\n",
      "196: max: 34.40625, min: 0.0\n",
      "Output shape for sample 043: torch.Size([1, 72, 57, 81]), True\n",
      "043: max: 35.625, min: 0.0\n",
      "Output shape for sample 060: torch.Size([1, 72, 57, 81]), True\n",
      "060: max: 34.0, min: 0.0\n",
      "Output shape for sample 271: torch.Size([1, 72, 57, 81]), True\n",
      "271: max: 10.4765625, min: 0.0\n",
      "Output shape for sample 198: torch.Size([1, 72, 57, 81]), True\n",
      "198: max: 21.21875, min: 0.0\n",
      "Output shape for sample 033: torch.Size([1, 72, 57, 81]), True\n",
      "033: max: 8.9140625, min: 0.0\n",
      "Output shape for sample 111: torch.Size([1, 72, 57, 81]), True\n",
      "111: max: 23.890625, min: 0.0\n",
      "Output shape for sample 119: torch.Size([1, 72, 57, 81]), True\n",
      "119: max: 11.8984375, min: 0.0\n",
      "Output shape for sample 212: torch.Size([1, 72, 57, 81]), True\n",
      "212: max: 7.44921875, min: 0.0\n",
      "Output shape for sample 007: torch.Size([1, 72, 57, 81]), True\n",
      "007: max: 7.73828125, min: 0.0\n",
      "Output shape for sample 213: torch.Size([1, 72, 57, 81]), True\n",
      "213: max: 35.875, min: 0.0\n",
      "Output shape for sample 167: torch.Size([1, 72, 57, 81]), True\n",
      "167: max: 11.7421875, min: 0.0\n",
      "Output shape for sample 081: torch.Size([1, 72, 57, 81]), True\n",
      "081: max: 7.1796875, min: 0.0\n",
      "Output shape for sample 098: torch.Size([1, 72, 57, 81]), True\n",
      "098: max: 32.125, min: 0.0\n",
      "Output shape for sample 024: torch.Size([1, 72, 57, 81]), True\n",
      "024: max: 17.703125, min: 0.0\n",
      "Output shape for sample 022: torch.Size([1, 72, 57, 81]), True\n",
      "022: max: 16.53125, min: 0.0\n",
      "Output shape for sample 070: torch.Size([1, 72, 57, 81]), True\n",
      "070: max: 43.5625, min: 0.0\n",
      "Output shape for sample 209: torch.Size([1, 72, 57, 81]), True\n",
      "209: max: 12.21875, min: 0.0\n",
      "Output shape for sample 067: torch.Size([1, 72, 57, 81]), True\n",
      "067: max: 8.90625, min: 0.0\n",
      "Output shape for sample 145: torch.Size([1, 72, 57, 81]), True\n",
      "145: max: 23.265625, min: 0.0\n",
      "Output shape for sample 041: torch.Size([1, 72, 57, 81]), True\n",
      "041: max: 6.1171875, min: 0.0\n",
      "Output shape for sample 235: torch.Size([1, 72, 57, 81]), True\n",
      "235: max: 26.859375, min: 0.0\n",
      "Output shape for sample 125: torch.Size([1, 72, 57, 81]), True\n",
      "125: max: 6.20703125, min: 0.0\n",
      "Output shape for sample 248: torch.Size([1, 72, 57, 81]), True\n",
      "248: max: 9.9140625, min: 0.0\n",
      "Output shape for sample 240: torch.Size([1, 72, 57, 81]), True\n",
      "240: max: 12.15625, min: 0.0\n",
      "Output shape for sample 233: torch.Size([1, 72, 57, 81]), True\n",
      "233: max: 42.625, min: 0.12396240234375\n",
      "Output shape for sample 035: torch.Size([1, 72, 57, 81]), True\n",
      "035: max: 44.65625, min: 0.0\n",
      "Output shape for sample 282: torch.Size([1, 72, 57, 81]), True\n",
      "282: max: 4.77734375, min: 0.0\n",
      "Output shape for sample 066: torch.Size([1, 72, 57, 81]), True\n",
      "066: max: 6.19140625, min: 0.0\n",
      "Output shape for sample 049: torch.Size([1, 72, 57, 81]), True\n",
      "049: max: 12.8671875, min: 0.0\n",
      "Output shape for sample 255: torch.Size([1, 72, 57, 81]), True\n",
      "255: max: 10.09375, min: 0.0\n",
      "Output shape for sample 200: torch.Size([1, 72, 57, 81]), True\n",
      "200: max: 23.984375, min: 0.0\n",
      "Output shape for sample 164: torch.Size([1, 72, 57, 81]), True\n",
      "164: max: 37.59375, min: 0.0\n",
      "Output shape for sample 269: torch.Size([1, 72, 57, 81]), True\n",
      "269: max: 8.6484375, min: 0.0\n",
      "Output shape for sample 137: torch.Size([1, 72, 57, 81]), True\n",
      "137: max: 49.71875, min: 0.0\n",
      "Output shape for sample 087: torch.Size([1, 72, 57, 81]), True\n",
      "087: max: 9.15625, min: 0.0\n",
      "Output shape for sample 106: torch.Size([1, 72, 57, 81]), True\n",
      "106: max: 27.703125, min: 0.0\n",
      "Output shape for sample 243: torch.Size([1, 72, 57, 81]), True\n",
      "243: max: 5.4921875, min: 0.0\n",
      "Output shape for sample 298: torch.Size([1, 72, 57, 81]), True\n",
      "298: max: 17.703125, min: 0.0\n",
      "Output shape for sample 229: torch.Size([1, 72, 57, 81]), True\n",
      "229: max: 11.265625, min: 0.0\n",
      "Output shape for sample 259: torch.Size([1, 72, 57, 81]), True\n",
      "259: max: 41.6875, min: 0.0\n",
      "Output shape for sample 014: torch.Size([1, 72, 57, 81]), True\n",
      "014: max: 17.5625, min: 0.0\n",
      "Output shape for sample 178: torch.Size([1, 72, 57, 81]), True\n",
      "178: max: 8.5234375, min: 0.0\n",
      "Output shape for sample 134: torch.Size([1, 72, 57, 81]), True\n",
      "134: max: 18.328125, min: 0.0\n",
      "Output shape for sample 100: torch.Size([1, 72, 57, 81]), True\n",
      "100: max: 12.0390625, min: 0.0\n",
      "Output shape for sample 160: torch.Size([1, 72, 57, 81]), True\n",
      "160: max: 17.859375, min: 0.0\n",
      "Output shape for sample 230: torch.Size([1, 72, 57, 81]), True\n",
      "230: max: 34.90625, min: 0.0\n",
      "Output shape for sample 142: torch.Size([1, 72, 57, 81]), True\n",
      "142: max: 6.78125, min: 0.0\n",
      "Output shape for sample 011: torch.Size([1, 72, 57, 81]), True\n",
      "011: max: 34.03125, min: 0.0\n",
      "Output shape for sample 005: torch.Size([1, 72, 57, 81]), True\n",
      "005: max: 9.7578125, min: 0.0\n",
      "Output shape for sample 140: torch.Size([1, 72, 57, 81]), True\n",
      "140: max: 3.87890625, min: 0.0\n",
      "Output shape for sample 061: torch.Size([1, 72, 57, 81]), True\n",
      "061: max: 38.25, min: 0.0\n",
      "Output shape for sample 221: torch.Size([1, 72, 57, 81]), True\n",
      "221: max: 8.734375, min: 0.0\n",
      "Output shape for sample 217: torch.Size([1, 72, 57, 81]), True\n",
      "217: max: 24.28125, min: 0.0\n",
      "Output shape for sample 147: torch.Size([1, 72, 57, 81]), True\n",
      "147: max: 26.203125, min: 0.0\n",
      "Output shape for sample 020: torch.Size([1, 72, 57, 81]), True\n",
      "020: max: 8.21875, min: 0.0\n",
      "Output shape for sample 232: torch.Size([1, 72, 57, 81]), True\n",
      "232: max: 33.03125, min: 0.0\n",
      "Output shape for sample 288: torch.Size([1, 72, 57, 81]), True\n",
      "288: max: 35.1875, min: 0.0\n",
      "Output shape for sample 292: torch.Size([1, 72, 57, 81]), True\n",
      "292: max: 10.6328125, min: 0.0\n",
      "Output shape for sample 139: torch.Size([1, 72, 57, 81]), True\n",
      "139: max: 0.91796875, min: 0.0\n",
      "Output shape for sample 237: torch.Size([1, 72, 57, 81]), True\n",
      "237: max: 5.53125, min: 0.0\n",
      "Output shape for sample 131: torch.Size([1, 72, 57, 81]), True\n",
      "131: max: 6.859375, min: 0.0\n",
      "Output shape for sample 123: torch.Size([1, 72, 57, 81]), True\n",
      "123: max: 4.87109375, min: 0.0\n",
      "Output shape for sample 029: torch.Size([1, 72, 57, 81]), True\n",
      "029: max: 14.3125, min: 0.0\n",
      "Output shape for sample 197: torch.Size([1, 72, 57, 81]), True\n",
      "197: max: 8.65625, min: 0.0\n",
      "Output shape for sample 296: torch.Size([1, 72, 57, 81]), True\n",
      "296: max: 12.5859375, min: 0.0\n",
      "Output shape for sample 225: torch.Size([1, 72, 57, 81]), True\n",
      "225: max: 24.34375, min: 0.0\n",
      "Output shape for sample 220: torch.Size([1, 72, 57, 81]), True\n",
      "220: max: 38.84375, min: 0.0\n",
      "Output shape for sample 105: torch.Size([1, 72, 57, 81]), True\n",
      "105: max: 11.5703125, min: 0.0\n",
      "Output shape for sample 172: torch.Size([1, 72, 57, 81]), True\n",
      "172: max: 10.4609375, min: 0.0\n",
      "Output shape for sample 279: torch.Size([1, 72, 57, 81]), True\n",
      "279: max: 10.9140625, min: 0.0\n",
      "Output shape for sample 013: torch.Size([1, 72, 57, 81]), True\n",
      "013: max: 19.328125, min: 0.0\n",
      "Output shape for sample 168: torch.Size([1, 72, 57, 81]), True\n",
      "168: max: 12.9296875, min: 0.0\n",
      "Output shape for sample 092: torch.Size([1, 72, 57, 81]), True\n",
      "092: max: 37.28125, min: 0.0\n",
      "Output shape for sample 036: torch.Size([1, 72, 57, 81]), True\n",
      "036: max: 21.359375, min: 0.0\n",
      "Output shape for sample 037: torch.Size([1, 72, 57, 81]), True\n",
      "037: max: 37.75, min: 0.0\n",
      "Output shape for sample 276: torch.Size([1, 72, 57, 81]), True\n",
      "276: max: 37.03125, min: 0.0\n",
      "Output shape for sample 059: torch.Size([1, 72, 57, 81]), True\n",
      "059: max: 7.44921875, min: 0.0\n",
      "Output shape for sample 050: torch.Size([1, 72, 57, 81]), True\n",
      "050: max: 11.875, min: 0.0\n",
      "Output shape for sample 250: torch.Size([1, 72, 57, 81]), True\n",
      "250: max: 38.71875, min: 0.0\n",
      "Output shape for sample 169: torch.Size([1, 72, 57, 81]), True\n",
      "169: max: 9.546875, min: 0.0\n",
      "Output shape for sample 008: torch.Size([1, 72, 57, 81]), True\n",
      "008: max: 44.0, min: 0.0\n",
      "Output shape for sample 295: torch.Size([1, 72, 57, 81]), True\n",
      "295: max: 7.89453125, min: 0.0\n",
      "Output shape for sample 110: torch.Size([1, 72, 57, 81]), True\n",
      "110: max: 10.0, min: 0.0\n",
      "Output shape for sample 146: torch.Size([1, 72, 57, 81]), True\n",
      "146: max: 25.015625, min: 0.0\n",
      "Output shape for sample 026: torch.Size([1, 72, 57, 81]), True\n",
      "026: max: 35.28125, min: 0.0\n",
      "Output shape for sample 010: torch.Size([1, 72, 57, 81]), True\n",
      "010: max: 50.34375, min: 0.0\n",
      "Output shape for sample 193: torch.Size([1, 72, 57, 81]), True\n",
      "193: max: 17.828125, min: 0.0\n",
      "Output shape for sample 257: torch.Size([1, 72, 57, 81]), True\n",
      "257: max: 38.375, min: 0.0\n",
      "Output shape for sample 090: torch.Size([1, 72, 57, 81]), True\n",
      "090: max: 33.78125, min: 0.0\n",
      "Output shape for sample 157: torch.Size([1, 72, 57, 81]), True\n",
      "157: max: 36.03125, min: 0.0\n",
      "Output shape for sample 189: torch.Size([1, 72, 57, 81]), True\n",
      "189: max: 7.18359375, min: 0.0\n",
      "Output shape for sample 161: torch.Size([1, 72, 57, 81]), True\n",
      "161: max: 49.46875, min: 0.0\n",
      "Output shape for sample 293: torch.Size([1, 72, 57, 81]), True\n",
      "293: max: 14.53125, min: 0.0\n",
      "Output shape for sample 074: torch.Size([1, 72, 57, 81]), True\n",
      "074: max: 5.3984375, min: 0.0\n",
      "Output shape for sample 109: torch.Size([1, 72, 57, 81]), True\n",
      "109: max: 12.96875, min: 0.0\n",
      "Output shape for sample 210: torch.Size([1, 72, 57, 81]), True\n",
      "210: max: 40.71875, min: 0.0\n",
      "Output shape for sample 001: torch.Size([1, 72, 57, 81]), True\n",
      "001: max: 18.140625, min: 0.0\n",
      "Output shape for sample 094: torch.Size([1, 72, 57, 81]), True\n",
      "094: max: 70.0, min: 0.0\n",
      "Output shape for sample 015: torch.Size([1, 72, 57, 81]), True\n",
      "015: max: 17.28125, min: 0.0\n",
      "Output shape for sample 285: torch.Size([1, 72, 57, 81]), True\n",
      "285: max: 10.984375, min: 0.0\n",
      "Output shape for sample 238: torch.Size([1, 72, 57, 81]), True\n",
      "238: max: 10.6015625, min: 0.0\n",
      "Output shape for sample 141: torch.Size([1, 72, 57, 81]), True\n",
      "141: max: 27.953125, min: 0.0\n",
      "Output shape for sample 104: torch.Size([1, 72, 57, 81]), True\n",
      "104: max: 19.234375, min: 0.0\n",
      "Output shape for sample 021: torch.Size([1, 72, 57, 81]), True\n",
      "021: max: 52.5625, min: 0.0\n",
      "Output shape for sample 117: torch.Size([1, 72, 57, 81]), True\n",
      "117: max: 12.2890625, min: 0.0\n",
      "Output shape for sample 252: torch.Size([1, 72, 57, 81]), True\n",
      "252: max: 8.03125, min: 0.0\n",
      "Output shape for sample 216: torch.Size([1, 72, 57, 81]), True\n",
      "216: max: 15.0703125, min: 0.0\n",
      "Output shape for sample 294: torch.Size([1, 72, 57, 81]), True\n",
      "294: max: 9.875, min: 0.0\n",
      "Output shape for sample 095: torch.Size([1, 72, 57, 81]), True\n",
      "095: max: 12.1328125, min: 0.0\n",
      "Output shape for sample 048: torch.Size([1, 72, 57, 81]), True\n",
      "048: max: 38.25, min: 0.0\n",
      "Output shape for sample 290: torch.Size([1, 72, 57, 81]), True\n",
      "290: max: 44.09375, min: 0.0\n",
      "Output shape for sample 040: torch.Size([1, 72, 57, 81]), True\n",
      "040: max: 3.11328125, min: 0.0\n",
      "Output shape for sample 165: torch.Size([1, 72, 57, 81]), True\n",
      "165: max: 26.234375, min: 0.0\n",
      "Output shape for sample 251: torch.Size([1, 72, 57, 81]), True\n",
      "251: max: 23.71875, min: 0.0\n",
      "Output shape for sample 158: torch.Size([1, 72, 57, 81]), True\n",
      "158: max: 27.90625, min: 0.0\n",
      "Output shape for sample 052: torch.Size([1, 72, 57, 81]), True\n",
      "052: max: 36.46875, min: 0.0\n",
      "Output shape for sample 056: torch.Size([1, 72, 57, 81]), True\n",
      "056: max: 40.875, min: 1.4775390625\n",
      "Output shape for sample 192: torch.Size([1, 72, 57, 81]), True\n",
      "192: max: 3.904296875, min: 0.0\n",
      "Output shape for sample 272: torch.Size([1, 72, 57, 81]), True\n",
      "272: max: 12.2734375, min: 0.0\n",
      "Output shape for sample 154: torch.Size([1, 72, 57, 81]), True\n",
      "154: max: 21.359375, min: 0.0\n",
      "Output shape for sample 153: torch.Size([1, 72, 57, 81]), True\n",
      "153: max: 42.40625, min: 0.0\n",
      "Output shape for sample 253: torch.Size([1, 72, 57, 81]), True\n",
      "253: max: 12.8203125, min: 0.0\n",
      "Output shape for sample 191: torch.Size([1, 72, 57, 81]), True\n",
      "191: max: 38.65625, min: 0.0\n",
      "Output shape for sample 047: torch.Size([1, 72, 57, 81]), True\n",
      "047: max: 39.0625, min: 0.0\n",
      "Output shape for sample 053: torch.Size([1, 72, 57, 81]), True\n",
      "053: max: 20.546875, min: 0.0\n",
      "Output shape for sample 129: torch.Size([1, 72, 57, 81]), True\n",
      "129: max: 14.6640625, min: 0.0\n",
      "Output shape for sample 188: torch.Size([1, 72, 57, 81]), True\n",
      "188: max: 7.5, min: 0.0\n",
      "Output shape for sample 182: torch.Size([1, 72, 57, 81]), True\n",
      "182: max: 43.9375, min: 0.68896484375\n",
      "Output shape for sample 080: torch.Size([1, 72, 57, 81]), True\n",
      "080: max: 6.77734375, min: 0.0\n",
      "Output shape for sample 002: torch.Size([1, 72, 57, 81]), True\n",
      "002: max: 12.0546875, min: 0.0\n",
      "Output shape for sample 155: torch.Size([1, 72, 57, 81]), True\n",
      "155: max: 8.7890625, min: 0.0\n",
      "Output shape for sample 004: torch.Size([1, 72, 57, 81]), True\n",
      "004: max: 20.46875, min: 0.0\n",
      "Output shape for sample 173: torch.Size([1, 72, 57, 81]), True\n",
      "173: max: 40.71875, min: 0.0\n",
      "Output shape for sample 258: torch.Size([1, 72, 57, 81]), True\n",
      "258: max: 7.95703125, min: 0.0\n",
      "Output shape for sample 025: torch.Size([1, 72, 57, 81]), True\n",
      "025: max: 8.8515625, min: 0.0\n",
      "Output shape for sample 136: torch.Size([1, 72, 57, 81]), True\n",
      "136: max: 2.9609375, min: 0.0\n",
      "Output shape for sample 017: torch.Size([1, 72, 57, 81]), True\n",
      "017: max: 33.5, min: 0.0\n",
      "Output shape for sample 274: torch.Size([1, 72, 57, 81]), True\n",
      "274: max: 8.9140625, min: 0.0\n",
      "Output shape for sample 113: torch.Size([1, 72, 57, 81]), True\n",
      "113: max: 13.09375, min: 0.0\n",
      "Output shape for sample 284: torch.Size([1, 72, 57, 81]), True\n",
      "284: max: 41.96875, min: 2.203125\n",
      "Output shape for sample 181: torch.Size([1, 72, 57, 81]), True\n",
      "181: max: 9.7109375, min: 0.0\n",
      "Output shape for sample 018: torch.Size([1, 72, 57, 81]), True\n",
      "018: max: 4.76171875, min: 0.0\n",
      "Output shape for sample 128: torch.Size([1, 72, 57, 81]), True\n",
      "128: max: 54.59375, min: 0.0\n",
      "Output shape for sample 190: torch.Size([1, 72, 57, 81]), True\n",
      "190: max: 6.65625, min: 0.0\n",
      "Output shape for sample 077: torch.Size([1, 72, 57, 81]), True\n",
      "077: max: 7.5859375, min: 0.0\n",
      "Output shape for sample 023: torch.Size([1, 72, 57, 81]), True\n",
      "023: max: 6.39453125, min: 0.0\n",
      "Output shape for sample 135: torch.Size([1, 72, 57, 81]), True\n",
      "135: max: 11.5546875, min: 0.0\n",
      "Output shape for sample 244: torch.Size([1, 72, 57, 81]), True\n",
      "244: max: 8.3359375, min: 0.0\n",
      "Output shape for sample 202: torch.Size([1, 72, 57, 81]), True\n",
      "202: max: 13.421875, min: 0.0\n",
      "Output shape for sample 126: torch.Size([1, 72, 57, 81]), True\n",
      "126: max: 5.16015625, min: 0.0\n",
      "Output shape for sample 115: torch.Size([1, 72, 57, 81]), True\n",
      "115: max: 18.828125, min: 0.0\n",
      "Output shape for sample 127: torch.Size([1, 72, 57, 81]), True\n",
      "127: max: 45.15625, min: 0.0\n",
      "Output shape for sample 089: torch.Size([1, 72, 57, 81]), True\n",
      "089: max: 45.5, min: 0.0\n",
      "Output shape for sample 199: torch.Size([1, 72, 57, 81]), True\n",
      "199: max: 38.375, min: 0.0\n",
      "Output shape for sample 108: torch.Size([1, 72, 57, 81]), True\n",
      "108: max: 19.75, min: 0.0\n",
      "Output shape for sample 262: torch.Size([1, 72, 57, 81]), True\n",
      "262: max: 22.4375, min: 0.0\n",
      "Output shape for sample 184: torch.Size([1, 72, 57, 81]), True\n",
      "184: max: 46.125, min: 0.0\n",
      "Output shape for sample 254: torch.Size([1, 72, 57, 81]), True\n",
      "254: max: 35.0625, min: 0.0\n",
      "Output shape for sample 234: torch.Size([1, 72, 57, 81]), True\n",
      "234: max: 12.953125, min: 0.0\n",
      "Output shape for sample 064: torch.Size([1, 72, 57, 81]), True\n",
      "064: max: 14.546875, min: 0.0\n",
      "Output shape for sample 065: torch.Size([1, 72, 57, 81]), True\n",
      "065: max: 4.8125, min: 0.0\n",
      "Output shape for sample 055: torch.Size([1, 72, 57, 81]), True\n",
      "055: max: 23.734375, min: 0.0\n",
      "Output shape for sample 152: torch.Size([1, 72, 57, 81]), True\n",
      "152: max: 41.15625, min: 0.0\n",
      "Output shape for sample 283: torch.Size([1, 72, 57, 81]), True\n",
      "283: max: 6.79296875, min: 0.0\n",
      "Output shape for sample 084: torch.Size([1, 72, 57, 81]), True\n",
      "084: max: 43.21875, min: 0.0\n",
      "Output shape for sample 195: torch.Size([1, 72, 57, 81]), True\n",
      "195: max: 33.40625, min: 0.0\n",
      "Output shape for sample 267: torch.Size([1, 72, 57, 81]), True\n",
      "267: max: 33.6875, min: 0.0\n",
      "Output shape for sample 174: torch.Size([1, 72, 57, 81]), True\n",
      "174: max: 10.4453125, min: 0.0\n",
      "Output shape for sample 079: torch.Size([1, 72, 57, 81]), True\n",
      "079: max: 3.279296875, min: 0.0\n",
      "Output shape for sample 260: torch.Size([1, 72, 57, 81]), True\n",
      "260: max: 36.375, min: 0.0\n",
      "Output shape for sample 028: torch.Size([1, 72, 57, 81]), True\n",
      "028: max: 11.1484375, min: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "# Load the model weights\n",
    "model.load_state_dict(torch.load('model/model_weights_99.pth'))\n",
    "model.eval()\n",
    "import os\n",
    "\n",
    "test_data_path = \"test/weather.round1.test\"\n",
    "os.makedirs(\"./output\", exist_ok=True)\n",
    "for index, test_data_file in enumerate(os.listdir(test_data_path)):\n",
    "    test_data = torch.load(os.path.join(test_data_path, test_data_file))\n",
    "    test_data = test_data.cuda().float()\n",
    "    \n",
    "    # Forward pass\n",
    "    output_item = model(test_data)\n",
    "    output_item = output_item.to(torch.float16)\n",
    "    \n",
    "    # Print the output shape\n",
    "    print(f\"Output shape for sample {test_data_file.split('.')[0]}: {output_item.shape}, {output_item.dtype == torch.float16}\")\n",
    "    print(f\"{test_data_file.split('.')[0]}: max: {output_item.max()}, min: {output_item.min()}\")\n",
    "    \n",
    "    # Save the output\n",
    "    output_path = f\"output/{test_data_file}\"\n",
    "    torch.save(output_item.cpu(), output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-31T15:50:47.197897Z",
     "iopub.status.busy": "2024-07-31T15:50:47.197628Z",
     "iopub.status.idle": "2024-07-31T15:50:52.018421Z",
     "shell.execute_reply": "2024-07-31T15:50:52.017765Z",
     "shell.execute_reply.started": "2024-07-31T15:50:47.197877Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: output/ (stored 0%)\n",
      "updating: output/122.pt (deflated 24%)\n",
      "updating: output/228.pt (deflated 95%)\n",
      "updating: output/226.pt (deflated 76%)\n",
      "updating: output/227.pt (deflated 24%)\n",
      "updating: output/054.pt (deflated 24%)\n",
      "updating: output/176.pt (deflated 93%)\n",
      "updating: output/058.pt (deflated 96%)\n",
      "updating: output/183.pt (deflated 23%)\n",
      "updating: output/222.pt (deflated 81%)\n",
      "updating: output/299.pt (deflated 79%)\n",
      "updating: output/042.pt (deflated 99%)\n",
      "updating: output/012.pt (deflated 26%)\n",
      "updating: output/006.pt (deflated 27%)\n",
      "updating: output/194.pt (deflated 28%)\n",
      "updating: output/069.pt (deflated 42%)\n",
      "updating: output/143.pt (deflated 73%)\n",
      "updating: output/133.pt (deflated 94%)\n",
      "updating: output/163.pt (deflated 23%)\n",
      "updating: output/118.pt (deflated 78%)\n",
      "updating: output/000.pt (deflated 95%)\n",
      "updating: output/063.pt (deflated 24%)\n",
      "updating: output/264.pt (deflated 77%)\n",
      "updating: output/186.pt (deflated 25%)\n",
      "updating: output/266.pt (deflated 85%)\n",
      "updating: output/051.pt (deflated 24%)\n",
      "updating: output/247.pt (deflated 82%)\n",
      "updating: output/073.pt (deflated 92%)\n",
      "updating: output/107.pt (deflated 23%)\n",
      "updating: output/062.pt (deflated 100%)\n",
      "updating: output/034.pt (deflated 79%)\n",
      "updating: output/261.pt (deflated 77%)\n",
      "updating: output/068.pt (deflated 66%)\n",
      "updating: output/211.pt (deflated 26%)\n",
      "updating: output/245.pt (deflated 25%)\n",
      "updating: output/150.pt (deflated 41%)\n",
      "updating: output/071.pt (deflated 100%)\n",
      "updating: output/078.pt (deflated 79%)\n",
      "updating: output/175.pt (deflated 24%)\n",
      "updating: output/242.pt (deflated 98%)\n",
      "updating: output/223.pt (deflated 99%)\n",
      "updating: output/151.pt (deflated 26%)\n",
      "updating: output/156.pt (deflated 92%)\n",
      "updating: output/082.pt (deflated 50%)\n",
      "updating: output/231.pt (deflated 79%)\n",
      "updating: output/179.pt (deflated 95%)\n",
      "updating: output/275.pt (deflated 46%)\n",
      "updating: output/096.pt (deflated 27%)\n",
      "updating: output/149.pt (deflated 25%)\n",
      "updating: output/159.pt (deflated 77%)\n",
      "updating: output/102.pt (deflated 94%)\n",
      "updating: output/215.pt (deflated 25%)\n",
      "updating: output/201.pt (deflated 99%)\n",
      "updating: output/003.pt (deflated 84%)\n",
      "updating: output/099.pt (deflated 99%)\n",
      "updating: output/281.pt (deflated 23%)\n",
      "updating: output/273.pt (deflated 29%)\n",
      "updating: output/286.pt (deflated 90%)\n",
      "updating: output/046.pt (deflated 24%)\n",
      "updating: output/218.pt (deflated 100%)\n",
      "updating: output/144.pt (deflated 98%)\n",
      "updating: output/171.pt (deflated 26%)\n",
      "updating: output/101.pt (deflated 77%)\n",
      "updating: output/208.pt (deflated 26%)\n",
      "updating: output/185.pt (deflated 92%)\n",
      "updating: output/287.pt (deflated 99%)\n",
      "updating: output/207.pt (deflated 24%)\n",
      "updating: output/114.pt (deflated 24%)\n",
      "updating: output/162.pt (deflated 24%)\n",
      "updating: output/016.pt (deflated 24%)\n",
      "updating: output/219.pt (deflated 26%)\n",
      "updating: output/086.pt (deflated 24%)\n",
      "updating: output/278.pt (deflated 50%)\n",
      "updating: output/214.pt (deflated 26%)\n",
      "updating: output/093.pt (deflated 98%)\n",
      "updating: output/085.pt (deflated 96%)\n",
      "updating: output/091.pt (deflated 67%)\n",
      "updating: output/166.pt (deflated 25%)\n",
      "updating: output/031.pt (deflated 34%)\n",
      "updating: output/116.pt (deflated 25%)\n",
      "updating: output/204.pt (deflated 100%)\n",
      "updating: output/124.pt (deflated 100%)\n",
      "updating: output/297.pt (deflated 92%)\n",
      "updating: output/076.pt (deflated 71%)\n",
      "updating: output/032.pt (deflated 97%)\n",
      "updating: output/170.pt (deflated 29%)\n",
      "updating: output/030.pt (deflated 92%)\n",
      "updating: output/045.pt (deflated 80%)\n",
      "updating: output/039.pt (deflated 96%)\n",
      "updating: output/083.pt (deflated 90%)\n",
      "updating: output/132.pt (deflated 95%)\n",
      "updating: output/256.pt (deflated 93%)\n",
      "updating: output/187.pt (deflated 65%)\n",
      "updating: output/044.pt (deflated 92%)\n",
      "updating: output/239.pt (deflated 24%)\n",
      "updating: output/075.pt (deflated 27%)\n",
      "updating: output/088.pt (deflated 24%)\n",
      "updating: output/224.pt (deflated 73%)\n",
      "updating: output/205.pt (deflated 73%)\n",
      "updating: output/236.pt (deflated 70%)\n",
      "updating: output/120.pt (deflated 24%)\n",
      "updating: output/097.pt (deflated 27%)\n",
      "updating: output/291.pt (deflated 99%)\n",
      "updating: output/019.pt (deflated 99%)\n",
      "updating: output/249.pt (deflated 99%)\n",
      "updating: output/009.pt (deflated 57%)\n",
      "updating: output/121.pt (deflated 23%)\n",
      "updating: output/241.pt (deflated 23%)\n",
      "updating: output/038.pt (deflated 26%)\n",
      "updating: output/203.pt (deflated 86%)\n",
      "updating: output/270.pt (deflated 83%)\n",
      "updating: output/268.pt (deflated 95%)\n",
      "updating: output/277.pt (deflated 75%)\n",
      "updating: output/027.pt (deflated 94%)\n",
      "updating: output/206.pt (deflated 23%)\n",
      "updating: output/246.pt (deflated 54%)\n",
      "updating: output/265.pt (deflated 25%)\n",
      "updating: output/103.pt (deflated 99%)\n",
      "updating: output/263.pt (deflated 96%)\n",
      "updating: output/180.pt (deflated 98%)\n",
      "updating: output/112.pt (deflated 98%)\n",
      "updating: output/130.pt (deflated 98%)\n",
      "updating: output/138.pt (deflated 100%)\n",
      "updating: output/057.pt (deflated 25%)\n",
      "updating: output/148.pt (deflated 61%)\n",
      "updating: output/072.pt (deflated 44%)\n",
      "updating: output/177.pt (deflated 29%)\n",
      "updating: output/280.pt (deflated 24%)\n",
      "updating: output/289.pt (deflated 93%)\n",
      "updating: output/196.pt (deflated 25%)\n",
      "updating: output/043.pt (deflated 25%)\n",
      "updating: output/060.pt (deflated 24%)\n",
      "updating: output/271.pt (deflated 83%)\n",
      "updating: output/198.pt (deflated 46%)\n",
      "updating: output/033.pt (deflated 95%)\n",
      "updating: output/111.pt (deflated 23%)\n",
      "updating: output/119.pt (deflated 91%)\n",
      "updating: output/212.pt (deflated 99%)\n",
      "updating: output/007.pt (deflated 96%)\n",
      "updating: output/213.pt (deflated 26%)\n",
      "updating: output/167.pt (deflated 78%)\n",
      "updating: output/081.pt (deflated 99%)\n",
      "updating: output/098.pt (deflated 25%)\n",
      "updating: output/024.pt (deflated 97%)\n",
      "updating: output/022.pt (deflated 75%)\n",
      "updating: output/070.pt (deflated 24%)\n",
      "updating: output/209.pt (deflated 70%)\n",
      "updating: output/067.pt (deflated 94%)\n",
      "updating: output/145.pt (deflated 35%)\n",
      "updating: output/041.pt (deflated 99%)\n",
      "updating: output/235.pt (deflated 45%)\n",
      "updating: output/125.pt (deflated 99%)\n",
      "updating: output/248.pt (deflated 97%)\n",
      "updating: output/240.pt (deflated 64%)\n",
      "updating: output/233.pt (deflated 26%)\n",
      "updating: output/035.pt (deflated 35%)\n",
      "updating: output/282.pt (deflated 95%)\n",
      "updating: output/066.pt (deflated 99%)\n",
      "updating: output/049.pt (deflated 82%)\n",
      "updating: output/255.pt (deflated 98%)\n",
      "updating: output/200.pt (deflated 26%)\n",
      "updating: output/164.pt (deflated 24%)\n",
      "updating: output/269.pt (deflated 80%)\n",
      "updating: output/137.pt (deflated 66%)\n",
      "updating: output/087.pt (deflated 85%)\n",
      "updating: output/106.pt (deflated 76%)\n",
      "updating: output/243.pt (deflated 98%)\n",
      "updating: output/298.pt (deflated 88%)\n",
      "updating: output/229.pt (deflated 99%)\n",
      "updating: output/259.pt (deflated 25%)\n",
      "updating: output/014.pt (deflated 97%)\n",
      "updating: output/178.pt (deflated 92%)\n",
      "updating: output/134.pt (deflated 36%)\n",
      "updating: output/100.pt (deflated 92%)\n",
      "updating: output/160.pt (deflated 55%)\n",
      "updating: output/230.pt (deflated 26%)\n",
      "updating: output/142.pt (deflated 96%)\n",
      "updating: output/011.pt (deflated 35%)\n",
      "updating: output/005.pt (deflated 98%)\n",
      "updating: output/140.pt (deflated 99%)\n",
      "updating: output/061.pt (deflated 25%)\n",
      "updating: output/221.pt (deflated 81%)\n",
      "updating: output/217.pt (deflated 74%)\n",
      "updating: output/147.pt (deflated 23%)\n",
      "updating: output/020.pt (deflated 98%)\n",
      "updating: output/232.pt (deflated 39%)\n",
      "updating: output/288.pt (deflated 24%)\n",
      "updating: output/292.pt (deflated 93%)\n",
      "updating: output/139.pt (deflated 100%)\n",
      "updating: output/237.pt (deflated 99%)\n",
      "updating: output/131.pt (deflated 96%)\n",
      "updating: output/123.pt (deflated 99%)\n",
      "updating: output/029.pt (deflated 62%)\n",
      "updating: output/197.pt (deflated 95%)\n",
      "updating: output/296.pt (deflated 88%)\n",
      "updating: output/225.pt (deflated 39%)\n",
      "updating: output/220.pt (deflated 24%)\n",
      "updating: output/105.pt (deflated 94%)\n",
      "updating: output/172.pt (deflated 86%)\n",
      "updating: output/279.pt (deflated 65%)\n",
      "updating: output/013.pt (deflated 49%)\n",
      "updating: output/168.pt (deflated 97%)\n",
      "updating: output/092.pt (deflated 39%)\n",
      "updating: output/036.pt (deflated 35%)\n",
      "updating: output/037.pt (deflated 23%)\n",
      "updating: output/276.pt (deflated 25%)\n",
      "updating: output/059.pt (deflated 99%)\n",
      "updating: output/050.pt (deflated 47%)\n",
      "updating: output/250.pt (deflated 28%)\n",
      "updating: output/169.pt (deflated 82%)\n",
      "updating: output/008.pt (deflated 24%)\n",
      "updating: output/295.pt (deflated 96%)\n",
      "updating: output/110.pt (deflated 95%)\n",
      "updating: output/146.pt (deflated 25%)\n",
      "updating: output/026.pt (deflated 25%)\n",
      "updating: output/010.pt (deflated 26%)\n",
      "updating: output/193.pt (deflated 53%)\n",
      "updating: output/257.pt (deflated 28%)\n",
      "updating: output/090.pt (deflated 26%)\n",
      "updating: output/157.pt (deflated 23%)\n",
      "updating: output/189.pt (deflated 99%)\n",
      "updating: output/161.pt (deflated 24%)\n",
      "updating: output/293.pt (deflated 96%)\n",
      "updating: output/074.pt (deflated 99%)\n",
      "updating: output/109.pt (deflated 80%)\n",
      "updating: output/210.pt (deflated 24%)\n",
      "updating: output/001.pt (deflated 46%)\n",
      "updating: output/094.pt (deflated 22%)\n",
      "updating: output/015.pt (deflated 84%)\n",
      "updating: output/285.pt (deflated 94%)\n",
      "updating: output/238.pt (deflated 80%)\n",
      "updating: output/141.pt (deflated 23%)\n",
      "updating: output/104.pt (deflated 90%)\n",
      "updating: output/021.pt (deflated 72%)\n",
      "updating: output/117.pt (deflated 49%)\n",
      "updating: output/252.pt (deflated 94%)\n",
      "updating: output/216.pt (deflated 59%)\n",
      "updating: output/294.pt (deflated 90%)\n",
      "updating: output/095.pt (deflated 66%)\n",
      "updating: output/048.pt (deflated 25%)\n",
      "updating: output/290.pt (deflated 24%)\n",
      "updating: output/040.pt (deflated 100%)\n",
      "updating: output/165.pt (deflated 27%)\n",
      "updating: output/251.pt (deflated 36%)\n",
      "updating: output/158.pt (deflated 93%)\n",
      "updating: output/052.pt (deflated 25%)\n",
      "updating: output/056.pt (deflated 29%)\n",
      "updating: output/192.pt (deflated 99%)\n",
      "updating: output/272.pt (deflated 81%)\n",
      "updating: output/154.pt (deflated 41%)\n",
      "updating: output/153.pt (deflated 23%)\n",
      "updating: output/253.pt (deflated 96%)\n",
      "updating: output/191.pt (deflated 78%)\n",
      "updating: output/047.pt (deflated 24%)\n",
      "updating: output/053.pt (deflated 59%)\n",
      "updating: output/129.pt (deflated 62%)\n",
      "updating: output/188.pt (deflated 99%)\n",
      "updating: output/182.pt (deflated 30%)\n",
      "updating: output/080.pt (deflated 99%)\n",
      "updating: output/002.pt (deflated 90%)\n",
      "updating: output/155.pt (deflated 95%)\n",
      "updating: output/004.pt (deflated 71%)\n",
      "updating: output/173.pt (deflated 25%)\n",
      "updating: output/258.pt (deflated 95%)\n",
      "updating: output/025.pt (deflated 83%)\n",
      "updating: output/136.pt (deflated 99%)\n",
      "updating: output/017.pt (deflated 27%)\n",
      "updating: output/274.pt (deflated 99%)\n",
      "updating: output/113.pt (deflated 87%)\n",
      "updating: output/284.pt (deflated 30%)\n",
      "updating: output/181.pt (deflated 94%)\n",
      "updating: output/018.pt (deflated 97%)\n",
      "updating: output/128.pt (deflated 22%)\n",
      "updating: output/190.pt (deflated 99%)\n",
      "updating: output/077.pt (deflated 99%)\n",
      "updating: output/023.pt (deflated 92%)\n",
      "updating: output/135.pt (deflated 50%)\n",
      "updating: output/244.pt (deflated 98%)\n",
      "updating: output/202.pt (deflated 78%)\n",
      "updating: output/126.pt (deflated 99%)\n",
      "updating: output/115.pt (deflated 22%)\n",
      "updating: output/127.pt (deflated 24%)\n",
      "updating: output/089.pt (deflated 24%)\n",
      "updating: output/199.pt (deflated 24%)\n",
      "updating: output/108.pt (deflated 79%)\n",
      "updating: output/262.pt (deflated 23%)\n",
      "updating: output/184.pt (deflated 25%)\n",
      "updating: output/254.pt (deflated 27%)\n",
      "updating: output/234.pt (deflated 77%)\n",
      "updating: output/064.pt (deflated 50%)\n",
      "updating: output/065.pt (deflated 100%)\n",
      "updating: output/055.pt (deflated 24%)\n",
      "updating: output/152.pt (deflated 23%)\n",
      "updating: output/283.pt (deflated 93%)\n",
      "updating: output/084.pt (deflated 65%)\n",
      "updating: output/195.pt (deflated 25%)\n",
      "updating: output/267.pt (deflated 24%)\n",
      "updating: output/174.pt (deflated 97%)\n",
      "updating: output/079.pt (deflated 99%)\n",
      "updating: output/260.pt (deflated 27%)\n",
      "updating: output/028.pt (deflated 80%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r output.zip output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
