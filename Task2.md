#优化方向
##1. 定义数据集, 建立起训练数据和标签之间的关系；定义数据加载器(DataLoader)， 方便取数据进行训练
#优化Dataloader：
    预取因子：prefetch_factor参数可以设置为一个大于1的值，以允许DataLoader在当前批次处理时预加载额外的数据批次
    持久化工作进程：设置persistent_workers=True可以使得工作进程在数据加载完毕后不立即销毁，而是等待下一个epoch继续使用，这可以减少进程创建和销毁的开销。
    内存映射：如果数据集太大无法全部加载到内存中，可以考虑使用内存映射技术，即在需要时从磁盘读取数据。
    减少数据转换的重复计算：在初始化数据集时，对数据进行一次性的预处理，如归一化和转换，然后在后续的迭代中不再重复这些操作。
    使用pin_memory：当设置pin_memory=True时，DataLoader会将数据加载到CUDA的固定内存中，这可以加速数据从CPU到GPU的传输。
    合理设置batch_size：根据可用的内存和GPU资源，合理设置每个批次的大小，以避免内存不足的问题。
    使用shuffle和sampler：合理使用shuffle参数和自定义的sampler可以优化数据的读取顺序，有时可以提高训练效率。
    避免数据转换中的重复计算：在数据集中预先应用ToTensor和Normalize等转换，避免在每个epoch中重复这些操作。
    使用drop_last：如果数据集的最后一个批次不完整，使用drop_last=True可以丢弃它，以保持批次大小的一致性。
    直接使用数据切片：在某些情况下，直接使用数据集的切片可能比使用DataLoader更高效，尤其是在数据已经全部加载到内存中的情况下
##2. 定义模型, 利用PyTorch搭建网络，根据输入输出数据维度实例化模型
###加深网络深度：原baseline只有一个卷积层（conv）对于特征提取和学习的能力不足
LSTM类
Transformer类
CNN类
###数据压缩感知：
  模型剪枝
  模型量化
  神经网络架构搜索
  知识蒸馏

##3. 定义损失函数, 优化器, 训练周期, 训练模型并保存模型参数
  Adam最有
##4. 模型加载及推理(模型预测)，输入测试数据输出要提交的文件
